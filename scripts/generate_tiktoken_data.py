#!/usr/bin/env python3

import sys
import base64
import tiktoken # Requires: pip install tiktoken

def b64encode_str(data: bytes) -> str:
    """Base64 encode bytes and return as a string."""
    return base64.b64encode(data).decode('utf-8')

def generate_c_header(tiktoken_file_path: str, output_header_path: str, encoder_name: str):
    """
    Reads a .tiktoken file, extracts vocabulary and merges,
    and generates a C header file (tiktoken_data.h).
    """
    try:
        # Load the encoder using the tiktoken library
        # Note: This might download the file if not cached by tiktoken itself
        enc = tiktoken.load.load_tiktoken_bpe(tiktoken_file_path)
    except Exception as e:
        print(f"Error loading tiktoken file '{tiktoken_file_path}': {e}", file=sys.stderr)
        print("Ensure the file exists (run 'make deps_tiktoken') and the 'tiktoken' Python package is installed.", file=sys.stderr)
        sys.exit(1)

    mergeable_ranks = enc._mergeable_ranks # bpe ranks (dict[bytes, int])
    special_tokens = enc._special_tokens # dict[str, int]

    # The C++ code expects the vocabulary (token bytes -> int)
    # which is the inverse of mergeable_ranks keys mapped to their rank (ID)
    # and also includes special tokens.
    # Let's reconstruct the vocabulary as expected by the C++ code.
    # It seems the original C++ code used the *ranks* as IDs for regular tokens.
    token_vocab = {token_bytes: rank for token_bytes, rank in mergeable_ranks.items()}

    # Add special tokens (their bytes representation -> ID)
    for token_str, token_id in special_tokens.items():
        try:
            token_bytes = token_str.encode('utf-8') # Tiktoken uses utf-8 for special tokens internally
            token_vocab[token_bytes] = token_id
        except UnicodeEncodeError:
            print(f"Warning: Could not encode special token '{token_str}' to bytes. Skipping.", file=sys.stderr)


    # The C++ code also uses BPE merge ranks (pair of bytes -> rank/priority)
    # This seems to be directly available as mergeable_ranks, but let's verify structure.
    # The C++ code expects pairs {first_bytes, second_bytes} -> rank.
    # The tiktoken library stores {merged_bytes: rank}. We need the pairs that *produce* the merge.
    # This requires the BPE logic which tiktoken lib handles internally.
    # The original C++ code *did* have bpe_ranks. Let's try to extract them if possible,
    # otherwise, the C++ BPE logic might need adjustment or removal if we rely solely on vocab.
    #
    # UPDATE: Looking at the tiktoken library source or its loading mechanism might be needed
    # to get the original pairs. The `.tiktoken` file format is essentially:
    # line 1: version
    # line 2...N: b64(token_bytes) rank
    #
    # The `load_tiktoken_bpe` function processes this. Let's stick to what the C++ code *used*.
    # It used `tiktoken_vocab` (bytes -> id) and `tiktoken_bpe_merges` (pair_bytes -> rank).
    # We can get the vocab. Getting the exact merge pairs might be tricky without reimplementing
    # part of the BPE logic or finding where tiktoken lib stores them.
    #
    # Let's assume for now the C++ BPE logic might not be fully utilized if we can't extract
    # the exact pairs easily, or that the original `tiktoken_data.h` might have sourced
    # this differently. We will generate the vocab and special tokens which are definite.
    # We will leave the BPE merges empty for now, as the C++ code has a fallback.

    print(f"Generating {output_header_path} for encoder '{encoder_name}'...")
    print(f"Found {len(token_vocab)} vocabulary entries (incl. special).")
    # print(f"Found {len(bpe_merges)} BPE merges.") # If we could extract them

    with open(output_header_path, 'w', encoding='utf-8') as f:
        f.write("/*\n")
        f.write(f" * Generated by {sys.argv[0]}\n")
        f.write(f" * Source: {tiktoken_file_path}\n")
        f.write(" * Encoder: {encoder_name}\n")
        f.write(" * DO NOT EDIT MANUALLY!\n")
        f.write(" */\n\n")
        f.write("#ifndef TIKTOKEN_DATA_H\n")
        f.write("#define TIKTOKEN_DATA_H\n\n")
        f.write("#include <stddef.h> // For size_t\n\n")

        # --- Struct Definitions (matching original src/tiktoken_data.h) ---
        f.write("// Structure for special tokens\n")
        f.write("typedef struct {\n")
        f.write("    const char* token_b64;  // Base64 encoded token bytes\n")
        f.write("    int id;                 // Token ID\n")
        f.write("} tiktoken_special_token_t;\n\n")

        f.write("// Structure for vocabulary entries\n")
        f.write("typedef struct {\n")
        f.write("    const char* token_b64;  // Base64 encoded token bytes\n")
        f.write("    int id;                 // Token ID\n")
        f.write("} tiktoken_vocab_entry_t;\n\n")

        f.write("// Structure for BPE merges (rank determines priority)\n")
        f.write("typedef struct {\n")
        f.write("    const char* first_b64;  // Base64 encoded first part of the pair\n")
        f.write("    const char* second_b64; // Base64 encoded second part of the pair\n")
        f.write("    int rank;               // Merge rank (lower is higher priority)\n")
        f.write("} tiktoken_bpe_merge_t;\n\n")

        # --- Special Tokens ---
        f.write("// Special Tokens\n")
        f.write("static const tiktoken_special_token_t tiktoken_special_tokens[] = {\n")
        count = 0
        # Sort by ID for consistency
        for token_str, token_id in sorted(special_tokens.items(), key=lambda item: item[1]):
             try:
                token_bytes = token_str.encode('utf-8')
                b64_bytes = b64encode_str(token_bytes)
                f.write(f'    {{"{b64_bytes}", {token_id}}},\n')
                count += 1
             except UnicodeEncodeError:
                 pass # Already warned
        f.write("};\n")
        f.write(f"static const size_t TIKTOKEN_NUM_SPECIAL_TOKENS = {count};\n\n")

        # --- Vocabulary ---
        f.write("// Vocabulary (Token Bytes -> ID)\n")
        f.write("static const tiktoken_vocab_entry_t tiktoken_vocab[] = {\n")
        count = 0
        # Sort by ID for consistency
        for token_bytes, token_id in sorted(token_vocab.items(), key=lambda item: item[1]):
            # Skip special tokens here, they are listed separately above
            # Note: The original C++ code might have had them duplicated, check if needed.
            # Assuming they should only be in the special list for clarity.
            is_special = False
            try:
                token_str = token_bytes.decode('utf-8')
                if token_str in special_tokens and special_tokens[token_str] == token_id:
                    is_special = True
            except UnicodeDecodeError:
                pass # Definitely not a special token string if it's not valid utf-8

            if not is_special:
                b64_bytes = b64encode_str(token_bytes)
                f.write(f'    {{"{b64_bytes}", {token_id}}},\n')
                count += 1
        f.write("};\n")
        f.write(f"static const size_t TIKTOKEN_VOCAB_SIZE = {count};\n\n")

        # --- BPE Merges ---
        # As noted above, extracting the exact pairs {first, second} -> rank
        # from the loaded encoder isn't straightforward. The C++ code has a
        # fallback if bpe_ranks is empty. We will generate an empty list.
        f.write("// BPE Merges (First Bytes, Second Bytes -> Rank)\n")
        f.write("// NOTE: Extraction of exact merge pairs from tiktoken lib is non-trivial.\n")
        f.write("// The C++ code includes a fallback if this list is empty.\n")
        f.write("static const tiktoken_bpe_merge_t tiktoken_bpe_merges[] = {\n")
        # Example if we could get them: {{"Zmlyc3Q=", "c2Vjb25k", 0}},
        f.write("    // { Base64(first_bytes), Base64(second_bytes), rank }\n")
        f.write("};\n")
        f.write("static const size_t TIKTOKEN_NUM_MERGES = 0;\n\n") # Set count to 0

        f.write("#endif // TIKTOKEN_DATA_H\n")

    print(f"Successfully wrote {output_header_path}")


if __name__ == "__main__":
    if len(sys.argv) != 4:
        print(f"Usage: {sys.argv[0]} <input_tiktoken_file> <output_header_file> <encoder_name>", file=sys.stderr)
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]
    encoder_name = sys.argv[3]

    generate_c_header(input_file, output_file, encoder_name)
